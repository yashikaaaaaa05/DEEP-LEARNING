{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdsDIpUL95B8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download the cifar 10\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "#normalize the pixel values: 0 - 1\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "XkaWo-SJ_FPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a list of class names\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "LuEVdW-R_n9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "W4ak3UBAkcKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels)"
      ],
      "metadata": {
        "id": "rhcuzFncLpEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "id": "hj4I7DPvLrvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_labels)"
      ],
      "metadata": {
        "id": "4IzLlyJ3LweQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "for i in range(25):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(train_images[i])\n",
        "  plt.xlabel(class_names[train_labels[i][0]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fy_0LiN8AEmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting: two ways:\n",
        "\n",
        "1. hyperparameter tuning, then if still overfitting is present, go to step 2\n",
        "\n",
        "2. Placing the overfitting techniques\n",
        "\n",
        "**Reason: Memorization** : same input data passing through similar architecture in each round of training\n",
        "\n",
        "Techniques:\n",
        "\n",
        "1. Regularization\n",
        "\n",
        "2. Add Dropout layers: changing the architecture with each round of training\n",
        "\n",
        "with each round of training, it will attach a prob of nodes being dropped from the architecture, p = 0.5 (p represents prob. of a node being retained)\n",
        "\n",
        "0.5 prob. of each node being retained and remaining 0.5 is the prob. of a node being dropped from the architecture\n",
        "\n",
        "3. BatchNormalisation:\n",
        "\n",
        "Normalisation: same range of data, mean=median=mode\n",
        "\n",
        "scaling range of pixel values b/w 0 to 1\n",
        "\n",
        "normalised data is feeded to neural networks in the first round of training\n",
        "\n",
        "batch 1: normalised data is feeded and processed (feature identification & extraction). The pixel values (features) of the ouotput will go out of the range of 0 to 1 (result of matrix multiplication)\n",
        "\n",
        "batch 2: output of batch 1 will become input to batch 2. Here, the pixel values or the features are not in normalised state.\n",
        "\n",
        "our objective is that ouput of every batch is normalised before feeding as input to the next batch\n",
        "\n",
        "this is what is done by batchnormalisation\n",
        "\n",
        "after every batch, it will compute the mean and stdev of the feature values and will scale or normalise them before feeding it to the next batch\n",
        "\n",
        "4. Early Stopping:\n",
        "\n",
        "epochs is a very significant hyper-parameter, too many epochs will lead to memorization issues.\n",
        "\n",
        "instruct the algo to stop early if it feels that further improvisation is not happening"
      ],
      "metadata": {
        "id": "lbJmxgXOpvQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))"
      ],
      "metadata": {
        "id": "xN57Z7eGGhpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "snlE10tGKx2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())"
      ],
      "metadata": {
        "id": "5n2OfdLJA28n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.MaxPool2D((2,2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(BatchNormalization())"
      ],
      "metadata": {
        "id": "asUO3d45Uk9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "mLCnGu3ab9GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform classification: we will add one or more dense layers\n",
        "\n",
        "Hidden or a dense layer of ANN: accept input in single dimension; flatten"
      ],
      "metadata": {
        "id": "QZ7laxMic2Qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#declare my ANN architecture\n",
        "model.add(layers.Flatten())#input layer\n",
        "model.add(layers.Dense(64, activation='relu'))#hidden layer\n",
        "model.add(layers.Dense(10))#output layer"
      ],
      "metadata": {
        "id": "byyXEWvyMHI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decalre my ANN architecture\n",
        "model.add(layers.Flatten())#input layer\n",
        "model.add(layers.Dense(64, activation='relu'))#hidden layer\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10))#output layer"
      ],
      "metadata": {
        "id": "zs2nI0DhcAaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decalre my ANN architecture\n",
        "model.add(layers.Flatten())#input layer\n",
        "model.add(layers.Dense(64, activation='relu'))#hidden layer\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dense(10))#output layer"
      ],
      "metadata": {
        "id": "eQB-opXiUxL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR8Q-BU8djHG",
        "outputId": "c86d0817-85bb-41ae-800d-bc7c3e789664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 30, 30, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 13, 13, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 4, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                65600     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,466\n",
            "Trainable params: 123,018\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "p_S4CjIrdkj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAqH6wB4eAaZ",
        "outputId": "d9b2de82-ea22-4083-b0de-6ca7d18ed88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 14s 7ms/step - loss: 1.3175 - accuracy: 0.5348\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9574 - accuracy: 0.6631\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8185 - accuracy: 0.7141\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7185 - accuracy: 0.7481\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6509 - accuracy: 0.7734\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.5854 - accuracy: 0.7968\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5305 - accuracy: 0.8145\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4770 - accuracy: 0.8313\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4400 - accuracy: 0.8453\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3992 - accuracy: 0.8602\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7834f169b790>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTiEKZDCeHpi",
        "outputId": "fe57f493-c44e-40e6-85bb-5596c9e69e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.9389 - accuracy: 0.7109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "metadata": {
        "id": "ffVc-XOFebic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "metadata": {
        "id": "F5GZUh3qemA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.argmax(predictions[0])"
      ],
      "metadata": {
        "id": "5gXoddeAenYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[0]"
      ],
      "metadata": {
        "id": "n9EF3fpxeqRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6oh4CDAe05R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}